{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/exterior/miniconda3/envs/project2/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/exterior/miniconda3/envs/project2/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/exterior/miniconda3/envs/project2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IO\n",
    "import os\n",
    "import csv\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import chardet\n",
    "import warnings\n",
    "\n",
    "# Utilities\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# Preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling and training\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, roc_auc_score,\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `nltk` resources (only needs to run once per machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt_tab: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping class (pytorch does not have a built in early stopping callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=1, restore_best_weights=True, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.mode = mode  # 'min' for loss, 'max' for accuracy, etc.\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, current_score, model):\n",
    "        # Determine if the current score is better\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            if self.restore_best_weights:\n",
    "                self.best_model_state = copy.deepcopy(model.state_dict())\n",
    "        elif (self.mode == 'min' and current_score < self.best_score) or \\\n",
    "             (self.mode == 'max' and current_score > self.best_score):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_model_state = copy.deepcopy(model.state_dict())\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def restore(self, model):\n",
    "        if self.restore_best_weights and self.best_model_state:\n",
    "            model.load_state_dict(self.best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df, vocab_inst):\n",
    "        self.vocab_inst = vocab_inst\n",
    "        self.texts = df['Sentence'].tolist()\n",
    "        self.labels = df['Sentiment_encoded'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoded = torch.tensor(encode_text(self.texts[idx]), dtype=torch.long)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return encoded, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpoSpeakDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size, \n",
    "        embed_dim=128, \n",
    "        lstm_out=196,\n",
    "        dropout_spatial=0.5, \n",
    "        dropout_lstm=0.3,\n",
    "        dropout_1=0.2,\n",
    "        dropout_2=0.4, \n",
    "        dense_1=100,\n",
    "        output_classes=3):\n",
    "        \n",
    "        super(CorpoSpeakDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)\n",
    "        self.spatial_dropout = nn.Dropout2d(p=dropout_spatial)  # Approximate SpatialDropout1D\n",
    "        self.lstm = nn.LSTM(embed_dim, lstm_out, batch_first=True, dropout=dropout_lstm)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(p=dropout_1)\n",
    "        self.dense_1 = nn.Linear(lstm_out, dense_1)\n",
    "        self.dropout_2 = nn.Dropout(p=dropout_2)\n",
    "        self.output_layer = nn.Linear(dense_1, output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                      # (batch, seq_len, embed_dim)\n",
    "        x = x.permute(0, 2, 1)                     # For Dropout2d: (batch, embed_dim, seq_len)\n",
    "        x = self.spatial_dropout(x)\n",
    "        x = x.permute(0, 2, 1)                     # Back to (batch, seq_len, embed_dim)\n",
    "        \n",
    "        x, _ = self.lstm(x)                        # LSTM returns (output, (h_n, c_n))\n",
    "        x = x[:, -1, :]                            # Get the output from the last timestep\n",
    "        \n",
    "        x = self.dropout_1(x)\n",
    "        x = F.relu(self.dense_1(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.output_layer(x)\n",
    "        return F.softmax(x, dim=1)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding of the text file is automatically detected here with some confidence. It could be extracted from terminal using\n",
    "```\n",
    "file -I file.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminal method (not os agnostic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!file -i ~/Documents/StudyResources/IML/Project/Part2/_data/FinancialPhraseBank-v1.0/Sentences_50Agree.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_from_file(filepath):\n",
    "    \"\"\"Given an input txt file, extract sentences \n",
    "    and associated sentiments\n",
    "\n",
    "    Args:\n",
    "        filepath (string): path to string \n",
    "\n",
    "    Returns:\n",
    "        list: list of sentences and sentiments\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    # automatically detect endoding (best guess)\n",
    "    with open(filepath, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "    # read and split\n",
    "    with open(filepath, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if '.@' in line:\n",
    "                sentence, sentiment = line.rsplit('.@', 1)\n",
    "                sentence = sentence.strip()\n",
    "                sentiment = sentiment.strip().lower()\n",
    "                sentence = fix_common_mojibake(sentence)\n",
    "                sentences.append((sentence, sentiment))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_csv(txt_path, output_csv):\n",
    "    \"\"\"Takes a file path as input and generates a .csv file\n",
    "    which contains sentences and sentiments as columns, extracted\n",
    "    from the .txt file corresponding to the path\n",
    "\n",
    "    Args:\n",
    "        txt_path (string): path to the .txt file\n",
    "        output_csv (string): path to desired output .csv file\n",
    "    \"\"\"\n",
    "    # Skip processing if CSV already exists\n",
    "    if os.path.exists(output_csv):\n",
    "        print(f\"{output_csv} already exists. Skipping processing.\")\n",
    "        return\n",
    "\n",
    "    sentences = extract_sentences_from_file(txt_path)\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Sentence', 'Sentiment'])  # Header\n",
    "        writer.writerows(sentences)\n",
    "    print(f\"Processed files and wrote output to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is needed as the text files seem to be corrupted, for example one sentence is:\n",
    "```\n",
    "Clothing retail chain Sepp+ñl+ñ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004\n",
    "```\n",
    "The characters `+ñ` are a result of choosing the wrong encoding; in fact, here the detected encoding is latin-1, and those characters correspond to `ä` in utf-8. The function below is used to fix these common mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_common_mojibake(text):\n",
    "    \"\"\"Function to manually handle encoding errors\n",
    "\n",
    "    Args:\n",
    "        text (string): input sentence\n",
    "\n",
    "    Returns:\n",
    "        string: output corrected sentence\n",
    "    \"\"\"\n",
    "    replacements = {\n",
    "        '+ñ': 'ä',\n",
    "        '+í': 'é',\n",
    "        '+ô': 'ö',\n",
    "        '+ü': 'ü'\n",
    "        }\n",
    "    for wrong, right in replacements.items():\n",
    "        text = text.replace(wrong, right)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function summarizes the common preprocessing pipeline for natural language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that creates csv files (if not created already) and returns the dataframe extracted from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    \"\"\"Import data and creates csv's and pandas dataframes\n",
    "\n",
    "    Returns:\n",
    "        pandas dataframes for training and testing\n",
    "    \"\"\"\n",
    "    print(\"Please select which dataset to use. Data is categorized based on the percentage of agreement in the sentiment estimator.\")\n",
    "    print(\"Options:\")\n",
    "    print(\"(1) 50\")\n",
    "    print(\"(2) 66\")\n",
    "    print(\"(3) 75\")\n",
    "    print(\"(4) 100\")\n",
    "    percentage = input()\n",
    "    if percentage=='50':\n",
    "        txt_path = RAW_DATA_FOLDER + 'Sentences_50Agree.txt'\n",
    "        csv_path = DATASET_FOLDER + 'sentences_50.csv'\n",
    "        txt_to_csv(txt_path, csv_path)\n",
    "    elif percentage=='66':\n",
    "        txt_path = RAW_DATA_FOLDER + 'Sentences_66Agree.txt'\n",
    "        csv_path = DATASET_FOLDER + 'sentences_66.csv'\n",
    "        txt_to_csv(txt_path, csv_path)\n",
    "    elif percentage=='75':\n",
    "        txt_path = RAW_DATA_FOLDER + 'Sentences_75Agree.txt'\n",
    "        csv_path = DATASET_FOLDER + 'sentences_75.csv'\n",
    "        txt_to_csv(txt_path, csv_path)\n",
    "    elif percentage=='100':\n",
    "        txt_path = RAW_DATA_FOLDER + 'Sentences_AllAgree.txt'\n",
    "        csv_path = DATASET_FOLDER + 'sentences_100.csv'\n",
    "        txt_to_csv(txt_path, csv_path)\n",
    "    else:\n",
    "        print(\"The percentage provided is not admitted, skipping.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df['Sentiment'])\n",
    "    df['Sentiment_encoded'] = le.transform(df['Sentiment'])\n",
    "\n",
    "    return df, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_df, val_df, vocab_inst=None):\n",
    "    if vocab_inst is None:\n",
    "        vocab_inst = build_vocab(train_df)\n",
    "\n",
    "    train_dataset = TextDataset(train_df, vocab_inst)\n",
    "    val_dataset = TextDataset(val_df, vocab_inst)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader, vocab_inst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are needed to create token vocabulary and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(df):\n",
    "    counter = Counter()\n",
    "    for text in df['Sentence']:\n",
    "        counter.update(preprocess_text(text))\n",
    "\n",
    "    vocab_inst = vocab(counter, specials=[\"<pad>\", \"<unk>\"])\n",
    "    vocab_inst.set_default_index(vocab_inst[\"<unk>\"])\n",
    "    return vocab_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text, vocab_inst):\n",
    "    tokens = preprocess_text(text)\n",
    "    return [vocab_inst[token] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, vocab_inst):\n",
    "    texts, labels = zip(*batch)\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=vocab_inst[\"<pad>\"])\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "Maybe it's better to feed it the dictionary generated outside of the objective function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(\n",
    "    trial, \n",
    "    df, \n",
    "    model_class,\n",
    "    device\n",
    "    ):\n",
    "    # Sample hyperparameters\n",
    "    embed_dim = trial.suggest_int(\"embed_dim\", 64, 256, step=32)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    wd = trial.suggest_float(\"weight_decay\", 1e-4, 1e-2, log=True)\n",
    "    lstm_out = trial.suggest_int(\"lstm_out\", 64, 256, step=32)\n",
    "    dropout_spatial = trial.suggest_float(\"dropout_spatial\", 0.1, 0.5, step=0.2)\n",
    "    dropout_lstm = trial.suggest_float(\"dropout_lstm\", 0.1, 0.5, step=0.2)\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0.1, 0.5, step=0.2)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0.1, 0.5, step=0.2)\n",
    "    dense_1 = trial.suggest_int(\"dense_1\", 64, 256, step=64)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_idx, val_idx in skf.split(df, df['Sentiment_encoded']):\n",
    "\n",
    "        early_stop = EarlyStopping(mode='max')\n",
    "\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # Build vocab only on training fold\n",
    "        vocab_inst = build_vocab(train_df)\n",
    "        vocab_size = len(vocab_inst)\n",
    "\n",
    "        train_loader, val_loader, _ = create_dataloaders(train_df, val_df, vocab_inst=vocab_inst)\n",
    "\n",
    "        # Define model (custom RNN or LSTM)\n",
    "        model = CorpoSpeakDecoder(\n",
    "            vocab_size, \n",
    "            embed_dim=embed_dim, \n",
    "            lstm_out=lstm_out,\n",
    "            dropout_spatial=dropout_spatial,\n",
    "            dropout_lstm=dropout_lstm, \n",
    "            dropout_1=dropout_1,\n",
    "            dropout_2=dropout_2,\n",
    "            dense_1=dense_1\n",
    "            )\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        loss_crit = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        # Train for 5 epochs for speed (or early stopping)\n",
    "        for _ in range(5):\n",
    "            _, _ = training_epoch(model, optimizer, loss_crit, train_loader, device)\n",
    "            val_loss, val_acc = validation_epoch(model, loss_crit, val_loader, device)\n",
    "\n",
    "            early_stop(val_acc, model)\n",
    "            if early_stop.early_stop:\n",
    "                early_stop.restore(model)\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # Evaluate on validation fold\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                output = model(x_val)\n",
    "                pred = torch.argmax(output, dim=1)\n",
    "                correct += (pred == y_val).sum().item()\n",
    "                total += y_val.size(0)\n",
    "\n",
    "        fold_acc = correct / total\n",
    "        accuracies.append(fold_acc)\n",
    "\n",
    "    # Return average CV accuracy\n",
    "    return sum(accuracies) / len(accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model, optimizer, loss_crit, train_loader, device):\n",
    "    model.train()\n",
    "    avg_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Load batches and train\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # Move data to device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_crit(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate train loss\n",
    "        avg_train_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "        # Accumulate train accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == batch_y).sum().item()\n",
    "        total_train += batch_y.size(0)\n",
    "    \n",
    "    # Average training loss and accuracy over batches\n",
    "    avg_train_loss /= total_train\n",
    "    avg_train_accuracy = correct_train / total_train\n",
    "\n",
    "    return avg_train_loss, avg_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    avg_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    \n",
    "    with torch.no_grad(): # No training\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # Move data to device\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "            # Accumulate train loss\n",
    "            avg_val_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "            # Accumulate validation accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == batch_y).sum().item()\n",
    "            total_val += batch_y.size(0)\n",
    "\n",
    "    \n",
    "    # Average validation loss for the fold\n",
    "    avg_val_loss /= total_val\n",
    "    avg_val_accuracy = correct_val / total_val\n",
    "    \n",
    "    return avg_val_loss, avg_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    df_train,\n",
    "    vocab_inst,\n",
    "    optimizer,\n",
    "    loss_crit,\n",
    "    device,\n",
    "    hyperparameters,\n",
    "    num_epochs=10,\n",
    "    early_stopping=None\n",
    "    ):\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        df_train,\n",
    "        test_size=val_size,\n",
    "        stratify=train_val_df[\"Sentiment_encoded\"],\n",
    "        random_state=42\n",
    "        )\n",
    "\n",
    "    train_loader, val_loader, vocab_inst = create_dataloaders(train_df, val_df, vocab_inst=vocab_inst)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "        }\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        # Training step\n",
    "        train_loss, train_acc = training_epoch(model, optimizer, loss_crit, train_loader, device)\n",
    "\n",
    "        # Validation step\n",
    "        val_loss, val_acc = validation_epoch(model, loss_crit, val_loader, device)\n",
    "\n",
    "        # Log metrics\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Optional: early stopping\n",
    "        if early_stopping:\n",
    "            early_stopping(val_acc, model, mode='max')\n",
    "            if early_stop.early_stop:\n",
    "                early_stop.restore(model)\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_sklearn(model, dataloader, num_classes, device='cpu'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probs = outputs.detach().cpu().numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    print(\"📊 Evaluation Results\")\n",
    "    print(\"-------------------------\")\n",
    "    print(f\"Accuracy         : {accuracy_score(all_labels, all_preds):.4f}\")\n",
    "    print(f\"Precision (macro): {precision_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "    print(f\"Recall    (macro): {recall_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "    print(f\"F1 Score  (macro): {f1_score(all_labels, all_preds, average='macro'):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "    # Binarize the labels for ROC computation\n",
    "    y_true_bin = label_binarize(all_labels, classes=np.arange(num_classes))\n",
    "\n",
    "    # Compute ROC curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], all_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute macro-average ROC curve and AUC\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    mean_tpr /= num_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    print(f\"\\nROC-AUC (macro-average): {roc_auc['macro']:.4f}\")\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f\"Macro Avg (AUC = {roc_auc['macro']:.2f})\", \n",
    "             linestyle='--', color='navy')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multiclass ROC Curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO multiple folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS-agnostic working folder and data folder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CodeDirectory = Path(os.path.abspath(''))\n",
    "DATASET_FOLDER = os.path.join(str(CodeDirectory.parent.absolute()), \"_data\",\"\")\n",
    "RAW_DATA_FOLDER = os.path.join(str(DATASET_FOLDER), \"FinancialPhraseBank-v1.0\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_path = DATASET_FOLDER+'data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select which dataset to use. Data is categorized based on the percentage of agreement in the sentiment estimator.\n",
      "Options:\n",
      "(1) 50\n",
      "(2) 66\n",
      "(3) 75\n",
      "(4) 100\n",
      "/Users/exterior/Documents/IML/Project/Part2/_data/sentences_50.csv already exists. Skipping processing.\n"
     ]
    }
   ],
   "source": [
    "df, le = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4730 entries, 0 to 4729\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Sentence           4730 non-null   object\n",
      " 1   Sentiment          4730 non-null   object\n",
      " 2   Sentiment_encoded  4730 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 111.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"Sentiment_encoded\"],\n",
    "    random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inst = build_vocab(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloaders from pandas dataframe. Text preprocessing is handled internally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
